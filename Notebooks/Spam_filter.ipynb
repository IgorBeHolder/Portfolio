{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Igor Sorochan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of text messages (simple spam filter)\n",
    "\n",
    "Usage of base Linear Regression model for classification of text messages ([dataset](https://github.com/obulygin/pyda_homeworks/blob/master/stat_case_study/spam.csv)) for spam as a target feature. \n",
    "\n",
    "Algorithm:\n",
    "1. Convert all text to lower case;\n",
    "1. Remove non-word characters;\n",
    "1. Remove stopwords;\n",
    "1. Lemmatization;\n",
    "1. Convert messages to TF-IDF vectors.  \n",
    "1. Run LR\n",
    "\n",
    "1. Evaluate a confusion_matrix."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Prepare`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "# https://www.machinelearningplus.com/nlp/gensim-tutorial/\n",
    "#  gensim library effectively manages corpora texts\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_raw = pd.read_csv('https://github.com/obulygin/pyda_homeworks/blob/master/stat_case_study/spam.csv')\n",
    "df_raw = pd.read_csv('/Users/velo1/SynologyDrive/GIT_syno/data/spam.csv')\n",
    "# df_raw = pd.read_csv('Notebooks/spam.csv')\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/velo1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/velo1/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/velo1/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words('english')) # stopwords_set\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415,\n",
       " Category    0\n",
       " Message     0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.duplicated().sum(), df_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ham</td>\n",
       "      <td>As I entered my cabin my PA said, '' Happy B'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>spam</td>\n",
       "      <td>You are awarded a SiPix Digital Camera! call 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>ham</td>\n",
       "      <td>I know you are thinkin malaria. But relax, chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just sleeping..and surfing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "103       ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "154       ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "207       ham  As I entered my cabin my PA said, '' Happy B'd...\n",
       "223       ham                             Sorry, I'll call later\n",
       "326       ham                   No calls..messages..missed calls\n",
       "...       ...                                                ...\n",
       "5524     spam  You are awarded a SiPix Digital Camera! call 0...\n",
       "5535      ham  I know you are thinkin malaria. But relax, chi...\n",
       "5539      ham                         Just sleeping..and surfing\n",
       "5553      ham                        Hahaha..use your brain dear\n",
       "5558      ham                             Sorry, I'll call later\n",
       "\n",
       "[415 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[df_raw.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5157 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   is_spam  5157 non-null   int64 \n",
      " 1   Message  5157 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 120.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df_raw.drop(df_raw[df_raw.duplicated()].index)\n",
    "df.Category.replace({'ham':0, 'spam':1}, inplace= True)\n",
    "df.rename({'Category':'is_spam'}, axis= 1, inplace= True)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Analyze`\n",
    "#### `Tokenization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>Message</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[nd, time, tried, contact, u, u, pound, prize,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5157 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_spam                                            Message  \\\n",
       "0           0  Go until jurong point, crazy.. Available only ...   \n",
       "1           0                      Ok lar... Joking wif u oni...   \n",
       "2           1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3           0  U dun say so early hor... U c already then say...   \n",
       "4           0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...       ...                                                ...   \n",
       "5567        1  This is the 2nd time we have tried 2 contact u...   \n",
       "5568        0               Will ü b going to esplanade fr home?   \n",
       "5569        0  Pity, * was in mood for that. So...any other s...   \n",
       "5570        0  The guy did some bitching but I acted like i'd...   \n",
       "5571        0                         Rofl. Its true to its name   \n",
       "\n",
       "                                                  words  \n",
       "0     [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                        [ok, lar, joking, wif, u, oni]  \n",
       "2     [free, entry, wkly, comp, win, fa, cup, final,...  \n",
       "3         [u, dun, say, early, hor, u, c, already, say]  \n",
       "4        [nah, think, goes, usf, lives, around, though]  \n",
       "...                                                 ...  \n",
       "5567  [nd, time, tried, contact, u, u, pound, prize,...  \n",
       "5568                 [ü, b, going, esplanade, fr, home]  \n",
       "5569                          [pity, mood, suggestions]  \n",
       "5570  [guy, bitching, acted, like, interested, buyin...  \n",
       "5571                                 [rofl, true, name]  \n",
       "\n",
       "[5157 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower ->  subst. non-word character  ->  split  ->  remove stopwords\n",
    "df['words'] = df.Message.apply(lambda x:\n",
    " [word for word in re.sub('[\\W\\d]+', ' ', x.lower()).split() if word not in stopwords_set] )\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>Message</th>\n",
       "      <th>words</th>\n",
       "      <th>lemm_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>nah think go usf life around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[nd, time, tried, contact, u, u, pound, prize,...</td>\n",
       "      <td>nd time tried contact u u pound prize claim ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>pity mood suggestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5157 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_spam                                            Message  \\\n",
       "0           0  Go until jurong point, crazy.. Available only ...   \n",
       "1           0                      Ok lar... Joking wif u oni...   \n",
       "2           1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3           0  U dun say so early hor... U c already then say...   \n",
       "4           0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...       ...                                                ...   \n",
       "5567        1  This is the 2nd time we have tried 2 contact u...   \n",
       "5568        0               Will ü b going to esplanade fr home?   \n",
       "5569        0  Pity, * was in mood for that. So...any other s...   \n",
       "5570        0  The guy did some bitching but I acted like i'd...   \n",
       "5571        0                         Rofl. Its true to its name   \n",
       "\n",
       "                                                  words  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, wkly, comp, win, fa, cup, final,...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4        [nah, think, goes, usf, lives, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [nd, time, tried, contact, u, u, pound, prize,...   \n",
       "5568                 [ü, b, going, esplanade, fr, home]   \n",
       "5569                          [pity, mood, suggestions]   \n",
       "5570  [guy, bitching, acted, like, interested, buyin...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                               lemm_str  \n",
       "0     go jurong point crazy available bugis n great ...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry wkly comp win fa cup final tkts st ...  \n",
       "3                   u dun say early hor u c already say  \n",
       "4                   nah think go usf life around though  \n",
       "...                                                 ...  \n",
       "5567  nd time tried contact u u pound prize claim ea...  \n",
       "5568                        ü b going esplanade fr home  \n",
       "5569                               pity mood suggestion  \n",
       "5570  guy bitching acted like interested buying some...  \n",
       "5571                                     rofl true name  \n",
       "\n",
       "[5157 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# lemmatize -> to string to feed \n",
    "df['lemm_str'] = df.words.apply(lambda x: \n",
    "    ' '.join([wordnet_lemmatizer.lemmatize(word) for word in x]) )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = corpora.Dictionary([['love']])\n",
    "# dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf–idf` means term-frequency `times` inverse document-frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5157, 7101)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase = False, ngram_range= (1,1))\n",
    "# ngram_range= (1,1)  FN 34 FP 6\n",
    "# ngram_range= (1,2)  FN 51 FP 3\n",
    "# ngram_range= (1,3)  FN 69 FP 3\n",
    "# ngram_range= (2,2)  FN 109 FP 0\n",
    "\n",
    "# Learn vocabulary and idf, return document-term matrix.\n",
    "tfidf_matrix = tfidf.fit_transform(df.lemm_str)\n",
    "\n",
    "# Get output feature names for transformation.\n",
    "names = tfidf.get_feature_names_out()\n",
    "\n",
    "\n",
    "tfidf_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns= names)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>____</th>\n",
       "      <th>aa</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathi</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abeg</th>\n",
       "      <th>...</th>\n",
       "      <th>zf</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5157 rows × 7101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ____   aa  aah  aaniye  aaooooright  aathi   ab  abbey  abdomen  abeg  \\\n",
       "0      0.0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   0.0   \n",
       "1      0.0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   0.0   \n",
       "2      0.0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   0.0   \n",
       "3      0.0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   0.0   \n",
       "4      0.0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   0.0   \n",
       "...    ...  ...  ...     ...          ...    ...  ...    ...      ...   ...   \n",
       "5152   0.0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   0.0   \n",
       "5153   0.0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   0.0   \n",
       "5154   0.0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   0.0   \n",
       "5155   0.0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   0.0   \n",
       "5156   0.0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   0.0   \n",
       "\n",
       "      ...   zf  zhong  zindgi  zoe  zogtorius  zoom  zouk  zyada   èn  〨ud  \n",
       "0     ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "1     ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "2     ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "3     ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "4     ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "...   ...  ...    ...     ...  ...        ...   ...   ...    ...  ...  ...  \n",
       "5152  ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "5153  ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "5154  ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "5155  ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "5156  ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "\n",
       "[5157 rows x 7101 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf_matrix['upper_ind'] = df.Message.apply(lambda x: sum(True for c in x if c.isupper()) / len (x)) # uppercase index\n",
    "# tfidf_matrix['nonword_ind'] = df.apply(lambda row: len(row.lemm_str)/ len (row.Message), axis= 1)  # nonword index\n",
    "# tfidf_matrix['len']= df.Message.apply(lambda x: len(x)) # empirical criterion approximates the 'Euclidean distance'\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_matrix[tfidf_matrix.upper_ind.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.replace({np.nan:0},inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_ = tfidf_matrix[tfidf_matrix.upper_ind.isna()== False].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_matrix.iloc[index_]\n",
    "# df.reset_index().iloc[index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf_matrix\n",
    "y = df['is_spam']\n",
    "X.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.3, random_state= 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `LR`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `process pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# parameters = {\n",
    "#             # 'scaler': [StandardScaler()],\n",
    "# \t            'logit__tol': [1e-2],# 1e-3],           #Tolerance for stopping criteria.\n",
    "#               'logit__C': [ 7 ], # 5 ,  10],            # Regularization parameter.\n",
    "#               'logit__max_iter': [1000], # 5000, 10000],  \n",
    "#               # 'logit__multi_class': ['ovr','multinomial'],\n",
    "#               'logit__n_jobs':[-1]\n",
    "#                 }\n",
    "# pipe = Pipeline([\n",
    "#                   # ('scaler', StandardScaler()),\n",
    "#                  ('logit', LogisticRegression())])\n",
    "                                 \n",
    "# grid = GridSearchCV(pipe, parameters, cv=10).fit(X_train, y_train)\n",
    "\n",
    "# logit_optim_score = grid.score(X_test, y_test)\n",
    "# print(f'Training set best score: {grid.score(X_train, y_train):2.2f}')\n",
    "# print(f'Test set best score: {logit_optim_score:2.3f}')\n",
    "\n",
    "# Access the best set of parameters\n",
    "# best_params = grid.best_params_\n",
    "# print('\\nOptimal set of parameters:', best_params)\n",
    "\n",
    "# Stores the optimum model in best_pipe\n",
    "# best_pipe = grid.best_estimator_\n",
    "# print('\\nOptimal pipeline:', best_pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `LR using pipeline best params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 169 ms, sys: 260 ms, total: 429 ms\n",
      "Wall time: 25.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=7, max_iter=1000, n_jobs=-1, tol=0.01)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(tol= 1e-2, C= 7, max_iter= 1000, n_jobs= -1)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x for x in dir(lr) if '_' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 97.416%\n"
     ]
    }
   ],
   "source": [
    "# Return the mean accuracy on the given test data and labels.\n",
    "\n",
    "print(f'Model accuracy: {lr.score(X_test, y_test):.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model f1-score: 89.418%\n"
     ]
    }
   ],
   "source": [
    "# Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "\n",
    "# The F1 score can be interpreted as a harmonic mean of the precision and\n",
    "# recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "# The relative contribution of precision and recall to the F1 score are\n",
    "# equal. \n",
    "print(f'Model f1-score: {f1_score(y_test, lr.predict(X_test)) :.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(input, predicted):\n",
    "    if input == 0:\n",
    "        return 'TN' if predicted == 0 else 'FP'\n",
    "    else:\n",
    "        return 'TP' if predicted == 1 else 'FN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Predicted'] = lr.predict(tfidf_matrix)\n",
    "df['conf_matrix'] = df.apply(lambda row: conf_matrix(row['is_spam'], row['Predicted']), axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>lemm_str</th>\n",
       "      <th>is_spam</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>conf_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>call message missed call</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Did you hear about the new \"Divorce Barbie\"? It comes with all of Ken's stuff!</td>\n",
       "      <td>hear new divorce barbie come ken stuff</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Yup next stop.</td>\n",
       "      <td>yup next stop</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Your free ringtone is waiting to be collected. Simply text the password \"MIX\" to 85069 to verify. Get Usher and Britney. FML, PO Box 5249, MK17 92H. 450Ppw 16</td>\n",
       "      <td>free ringtone waiting collected simply text password mix verify get usher britney fml po box mk h ppw</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Call Germany for only 1 pence per minute! Call from a fixed line via access number 0844 861 85 85. No prepayment. Direct access!</td>\n",
       "      <td>call germany penny per minute call fixed line via access number prepayment direct access</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                            Message  \\\n",
       "45                                                                                                                                 No calls..messages..missed calls   \n",
       "68                                                                                   Did you hear about the new \"Divorce Barbie\"? It comes with all of Ken's stuff!   \n",
       "84                                                                                                                                                   Yup next stop.   \n",
       "95   Your free ringtone is waiting to be collected. Simply text the password \"MIX\" to 85069 to verify. Get Usher and Britney. FML, PO Box 5249, MK17 92H. 450Ppw 16   \n",
       "333                                Call Germany for only 1 pence per minute! Call from a fixed line via access number 0844 861 85 85. No prepayment. Direct access!   \n",
       "\n",
       "                                                                                                  lemm_str  \\\n",
       "45                                                                                call message missed call   \n",
       "68                                                                  hear new divorce barbie come ken stuff   \n",
       "84                                                                                           yup next stop   \n",
       "95   free ringtone waiting collected simply text password mix verify get usher britney fml po box mk h ppw   \n",
       "333               call germany penny per minute call fixed line via access number prepayment direct access   \n",
       "\n",
       "     is_spam  Predicted conf_matrix  \n",
       "45         0          1          FP  \n",
       "68         1          0          FN  \n",
       "84         0          1          FP  \n",
       "95         1          0          FN  \n",
       "333        1          0          FN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MISTAKES (FN + FP)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "df[df.is_spam != df.Predicted][['Message', 'lemm_str','is_spam','Predicted', 'conf_matrix']].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Share`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"wikitable\" style=\"border:none; background:transparent; text-align:center;\" align=\"center\">\n",
    "<tbody><tr>\n",
    "<td rowspan=\"2\" style=\"border:none;\">\n",
    "</td>\n",
    "<td style=\"border:none;\">\n",
    "</td>\n",
    "<td colspan=\"2\" style=\"background:#bbeeee;\"><b>Predicted condition</b>\n",
    "</td>\n",
    "\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background:#eeeeee;\"><a href=\"/wiki/Statistical_population\" title=\"Statistical population\">Total population</a> <br><span style=\"white-space:nowrap;\">= P + N</span>\n",
    "</td>\n",
    "<td style=\"background:#ccffff;\"><b>Positive (PP)</b>\n",
    "</td>\n",
    "<td style=\"background:#aadddd;\"><b>Negative (PN)</b>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td rowspan=\"2\" class=\"nowrap unsortable\" style=\"line-height:99%;vertical-align:middle;padding:.4em .4em .2em;background-position:50% .4em !important;min-width:0.875em;max-width:0.875em;width:0.875em;overflow:hidden;background:#eeeebb;\"><div style=\"vertical-rl=-webkit-writing-mode: vertical-rl; -o-writing-mode: vertical-rl; -ms-writing-mode: tb-rl;writing-mode: tb-rl; writing-mode: vertical-rl; layout-flow: vertical-ideographic;transform:rotate(180deg);display:inline-block;padding-left:1px;text-align:center;\"><b>Actual condition</b></div>\n",
    "</td>\n",
    "<td style=\"background:#ffffcc;\"><b>Positive (P)</b>\n",
    "</td>\n",
    "<td style=\"background:#ccffcc;\"><b><a href=\"/wiki/True_positive\" class=\"mw-redirect\" title=\"True positive\">True positive</a> (TP) <br></b>\n",
    "</td>\n",
    "<td style=\"background:#ffdddd;\"><b><a href=\"/wiki/False_negative\" class=\"mw-redirect\" title=\"False negative\">False negative</a> (FN) <br></b>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background:#ddddaa;\"><b>Negative (N)</b>\n",
    "</td>\n",
    "<td style=\"background:#ffcccc;\"><b><a href=\"/wiki/False_positive\" class=\"mw-redirect\" title=\"False positive\">False positive</a> (FP) <br></b>\n",
    "</td>\n",
    "<td style=\"background:#bbeebb;\"><b><a href=\"/wiki/True_negative\" class=\"mw-redirect\" title=\"True negative\">True negative</a> (TN) <br></b>\n",
    "</td></tr></tbody></table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Model overall (train+test) metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = df[['is_spam', 'conf_matrix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ae3cd_row0_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, lightgreen 0.9%, transparent 0.9%);\n",
       "}\n",
       "#T_ae3cd_row1_col0 {\n",
       "  width: 10em;\n",
       "}\n",
       "#T_ae3cd_row2_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, lightgreen 100.0%, transparent 100.0%);\n",
       "}\n",
       "#T_ae3cd_row3_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, lightgreen 13.0%, transparent 13.0%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ae3cd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ae3cd_level0_col0\" class=\"col_heading level0 col0\" >is_spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >conf_matrix</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ae3cd_level0_row0\" class=\"row_heading level0 row0\" >FN</th>\n",
       "      <td id=\"T_ae3cd_row0_col0\" class=\"data row0 col0\" >48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae3cd_level0_row1\" class=\"row_heading level0 row1\" >FP</th>\n",
       "      <td id=\"T_ae3cd_row1_col0\" class=\"data row1 col0\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae3cd_level0_row2\" class=\"row_heading level0 row2\" >TN</th>\n",
       "      <td id=\"T_ae3cd_row2_col0\" class=\"data row2 col0\" >4509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae3cd_level0_row3\" class=\"row_heading level0 row3\" >TP</th>\n",
       "      <td id=\"T_ae3cd_row3_col0\" class=\"data row3 col0\" >593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fef105a52e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = (df_cm['conf_matrix'] == 'TP').sum()\n",
    "TN = (df_cm['conf_matrix'] == 'TN').sum()\n",
    "FP = (df_cm['conf_matrix'] == 'FP').sum()\n",
    "FN = (df_cm['conf_matrix'] == 'FN').sum()\n",
    "P = (df_cm['is_spam'] == 1).sum()\n",
    "N = (df_cm['is_spam'] == 0).sum()\n",
    "\n",
    "df_cm.groupby('conf_matrix').count().style.bar(align='left', color='lightgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence             = 12.430 %\n",
      "TPR (sensivity, power, precision) = 92.512 %\n",
      "TNR (specificity)      = 99.845 %\n",
      "FPR (false alarm)      = 0.155 %\n",
      "FNR (miss rate)        = 7.488 %\n",
      "Accuracy               = 98.933 %\n",
      "F1 score               = 95.568 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Prevalence {\" \"*12}= {P /(P+N):0.3%}'.replace('%', ' %'))\n",
    "print(f'TPR (sensivity, power, precision) = {TP/P:0.3%}'.replace('%', ' %'))\n",
    "print(f'TNR (specificity){\" \"*6}= {TN/N:0.3%}'.replace('%', ' %'))\n",
    "print(f'FPR (false alarm){\" \"*6}= {FP/N:0.3%}'.replace('%', ' %'))\n",
    "print(f'FNR (miss rate){\" \"*8}= {FN/P:0.3%}'.replace('%', ' %'))\n",
    "print(f'Accuracy {\" \"*14}= {(TP+TN)/(P+N):0.3%}'.replace('%', ' %'))\n",
    "# F1 = 2*TP/(2*TP+FP+FN)\n",
    "print(f'F1 score {\" \"*14}= {2*TP/(2*TP+FP+FN):0.3%}'.replace('%', ' %'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Model metrics on test data only`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = df_cm.iloc[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7ca7a_row0_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, lightgreen 2.1%, transparent 2.1%);\n",
       "}\n",
       "#T_7ca7a_row1_col0 {\n",
       "  width: 10em;\n",
       "}\n",
       "#T_7ca7a_row2_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, lightgreen 100.0%, transparent 100.0%);\n",
       "}\n",
       "#T_7ca7a_row3_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, lightgreen 12.2%, transparent 12.2%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7ca7a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7ca7a_level0_col0\" class=\"col_heading level0 col0\" >is_spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >conf_matrix</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7ca7a_level0_row0\" class=\"row_heading level0 row0\" >FN</th>\n",
       "      <td id=\"T_7ca7a_row0_col0\" class=\"data row0 col0\" >34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ca7a_level0_row1\" class=\"row_heading level0 row1\" >FP</th>\n",
       "      <td id=\"T_7ca7a_row1_col0\" class=\"data row1 col0\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ca7a_level0_row2\" class=\"row_heading level0 row2\" >TN</th>\n",
       "      <td id=\"T_7ca7a_row2_col0\" class=\"data row2 col0\" >1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ca7a_level0_row3\" class=\"row_heading level0 row3\" >TP</th>\n",
       "      <td id=\"T_7ca7a_row3_col0\" class=\"data row3 col0\" >169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fef1077bfd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = (df_cm['conf_matrix'] == 'TP').sum()\n",
    "TN = (df_cm['conf_matrix'] == 'TN').sum()\n",
    "FP = (df_cm['conf_matrix'] == 'FP').sum()\n",
    "FN = (df_cm['conf_matrix'] == 'FN').sum()\n",
    "P = (df_cm['is_spam'] == 1).sum()\n",
    "N = (df_cm['is_spam'] == 0).sum()\n",
    "\n",
    "df_cm.groupby('conf_matrix').count().style.bar(align='left', color='lightgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence             = 13.114 %\n",
      "TPR (sensivity, power, precision) = 83.251 %\n",
      "TNR (specificity)      = 99.554 %\n",
      "FPR (false alarm)      = 0.446 %\n",
      "FNR (miss rate)        = 16.749 %\n",
      "Accuracy               = 97.416 %\n",
      "F1 score               = 89.418 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Prevalence {\" \"*12}= {P /(P+N):0.3%}'.replace('%', ' %'))\n",
    "print(f'TPR (sensivity, power, precision) = {TP/P:0.3%}'.replace('%', ' %'))\n",
    "print(f'TNR (specificity){\" \"*6}= {TN/N:0.3%}'.replace('%', ' %'))\n",
    "print(f'FPR (false alarm){\" \"*6}= {FP/N:0.3%}'.replace('%', ' %'))\n",
    "print(f'FNR (miss rate){\" \"*8}= {FN/P:0.3%}'.replace('%', ' %'))\n",
    "print(f'Accuracy {\" \"*14}= {(TP+TN)/(P+N):0.3%}'.replace('%', ' %'))\n",
    "# F1 = 2*TP/(2*TP+FP+FN)\n",
    "print(f'F1 score {\" \"*14}= {2*TP/(2*TP+FP+FN):0.3%}'.replace('%', ' %'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>Message</th>\n",
       "      <th>words</th>\n",
       "      <th>lemm_str</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>conf_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>[calls, messages, missed, calls]</td>\n",
       "      <td>call message missed call</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>Yup next stop.</td>\n",
       "      <td>[yup, next, stop]</td>\n",
       "      <td>yup next stop</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>Are you free now?can i call now?</td>\n",
       "      <td>[free, call]</td>\n",
       "      <td>free call</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>0</td>\n",
       "      <td>Can... I'm free...</td>\n",
       "      <td>[free]</td>\n",
       "      <td>free</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>0</td>\n",
       "      <td>When you get free, call me</td>\n",
       "      <td>[get, free, call]</td>\n",
       "      <td>get free call</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>0</td>\n",
       "      <td>I (Career Tel) have added u as a contact on INDYAROCKS.COM to send FREE SMS. To remove from phonebook - sms NO to  &amp;lt;#&amp;gt;</td>\n",
       "      <td>[career, tel, added, u, contact, indyarocks, com, send, free, sms, remove, phonebook, sms, lt, gt]</td>\n",
       "      <td>career tel added u contact indyarocks com send free sm remove phonebook sm lt gt</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>0</td>\n",
       "      <td>K k:) sms chat with me.</td>\n",
       "      <td>[k, k, sms, chat]</td>\n",
       "      <td>k k sm chat</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_spam  \\\n",
       "45          0   \n",
       "84          0   \n",
       "495         0   \n",
       "3364        0   \n",
       "4419        0   \n",
       "4729        0   \n",
       "5157        0   \n",
       "\n",
       "                                                                                                                           Message  \\\n",
       "45                                                                                                No calls..messages..missed calls   \n",
       "84                                                                                                                  Yup next stop.   \n",
       "495                                                                                               Are you free now?can i call now?   \n",
       "3364                                                                                                            Can... I'm free...   \n",
       "4419                                                                                                    When you get free, call me   \n",
       "4729  I (Career Tel) have added u as a contact on INDYAROCKS.COM to send FREE SMS. To remove from phonebook - sms NO to  &lt;#&gt;   \n",
       "5157                                                                                                       K k:) sms chat with me.   \n",
       "\n",
       "                                                                                                   words  \\\n",
       "45                                                                      [calls, messages, missed, calls]   \n",
       "84                                                                                     [yup, next, stop]   \n",
       "495                                                                                         [free, call]   \n",
       "3364                                                                                              [free]   \n",
       "4419                                                                                   [get, free, call]   \n",
       "4729  [career, tel, added, u, contact, indyarocks, com, send, free, sms, remove, phonebook, sms, lt, gt]   \n",
       "5157                                                                                   [k, k, sms, chat]   \n",
       "\n",
       "                                                                              lemm_str  \\\n",
       "45                                                            call message missed call   \n",
       "84                                                                       yup next stop   \n",
       "495                                                                          free call   \n",
       "3364                                                                              free   \n",
       "4419                                                                     get free call   \n",
       "4729  career tel added u contact indyarocks com send free sm remove phonebook sm lt gt   \n",
       "5157                                                                       k k sm chat   \n",
       "\n",
       "      Predicted conf_matrix  \n",
       "45            1          FP  \n",
       "84            1          FP  \n",
       "495           1          FP  \n",
       "3364          1          FP  \n",
       "4419          1          FP  \n",
       "4729          1          FP  \n",
       "5157          1          FP  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WE HAVE FALSE ALARM ON THESE MESSAGES\n",
    "df[df['conf_matrix'] == 'FP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>Message</th>\n",
       "      <th>words</th>\n",
       "      <th>lemm_str</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>conf_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>Did you hear about the new \"Divorce Barbie\"? It comes with all of Ken's stuff!</td>\n",
       "      <td>[hear, new, divorce, barbie, comes, ken, stuff]</td>\n",
       "      <td>hear new divorce barbie come ken stuff</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>Your free ringtone is waiting to be collected. Simply text the password \"MIX\" to 85069 to verify. Get Usher and Britney. FML, PO Box 5249, MK17 92H. 450Ppw 16</td>\n",
       "      <td>[free, ringtone, waiting, collected, simply, text, password, mix, verify, get, usher, britney, fml, po, box, mk, h, ppw]</td>\n",
       "      <td>free ringtone waiting collected simply text password mix verify get usher britney fml po box mk h ppw</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1</td>\n",
       "      <td>Call Germany for only 1 pence per minute! Call from a fixed line via access number 0844 861 85 85. No prepayment. Direct access!</td>\n",
       "      <td>[call, germany, pence, per, minute, call, fixed, line, via, access, number, prepayment, direct, access]</td>\n",
       "      <td>call germany penny per minute call fixed line via access number prepayment direct access</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>1</td>\n",
       "      <td>XCLUSIVE@CLUBSAISAI 2MOROW 28/5 SOIREE SPECIALE ZOUK WITH NICHOLS FROM PARIS.FREE ROSES 2 ALL LADIES !!! info: 07946746291/07880867867</td>\n",
       "      <td>[xclusive, clubsaisai, morow, soiree, speciale, zouk, nichols, paris, free, roses, ladies, info]</td>\n",
       "      <td>xclusive clubsaisai morow soiree speciale zouk nichols paris free rose lady info</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?</td>\n",
       "      <td>[realize, years, thousands, old, ladies, running, around, tattoos]</td>\n",
       "      <td>realize year thousand old lady running around tattoo</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_spam  \\\n",
       "68         1   \n",
       "95         1   \n",
       "333        1   \n",
       "607        1   \n",
       "751        1   \n",
       "\n",
       "                                                                                                                                                            Message  \\\n",
       "68                                                                                   Did you hear about the new \"Divorce Barbie\"? It comes with all of Ken's stuff!   \n",
       "95   Your free ringtone is waiting to be collected. Simply text the password \"MIX\" to 85069 to verify. Get Usher and Britney. FML, PO Box 5249, MK17 92H. 450Ppw 16   \n",
       "333                                Call Germany for only 1 pence per minute! Call from a fixed line via access number 0844 861 85 85. No prepayment. Direct access!   \n",
       "607                          XCLUSIVE@CLUBSAISAI 2MOROW 28/5 SOIREE SPECIALE ZOUK WITH NICHOLS FROM PARIS.FREE ROSES 2 ALL LADIES !!! info: 07946746291/07880867867   \n",
       "751                                                          Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?   \n",
       "\n",
       "                                                                                                                        words  \\\n",
       "68                                                                            [hear, new, divorce, barbie, comes, ken, stuff]   \n",
       "95   [free, ringtone, waiting, collected, simply, text, password, mix, verify, get, usher, britney, fml, po, box, mk, h, ppw]   \n",
       "333                   [call, germany, pence, per, minute, call, fixed, line, via, access, number, prepayment, direct, access]   \n",
       "607                          [xclusive, clubsaisai, morow, soiree, speciale, zouk, nichols, paris, free, roses, ladies, info]   \n",
       "751                                                        [realize, years, thousands, old, ladies, running, around, tattoos]   \n",
       "\n",
       "                                                                                                  lemm_str  \\\n",
       "68                                                                  hear new divorce barbie come ken stuff   \n",
       "95   free ringtone waiting collected simply text password mix verify get usher britney fml po box mk h ppw   \n",
       "333               call germany penny per minute call fixed line via access number prepayment direct access   \n",
       "607                       xclusive clubsaisai morow soiree speciale zouk nichols paris free rose lady info   \n",
       "751                                                   realize year thousand old lady running around tattoo   \n",
       "\n",
       "     Predicted conf_matrix  \n",
       "68           0          FN  \n",
       "95           0          FN  \n",
       "333          0          FN  \n",
       "607          0          FN  \n",
       "751          0          FN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WE MISS THESE spam MESSAGES\n",
    "df[df['conf_matrix'] == 'FN'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Main assumptions:``\n",
    "* `to maximize TNR (specificity, minimize false alarm) use n-grams (2,2)`\n",
    "* `to maximize TPR (sensivity, maximize spam detection) use n-grams(1,1)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Feature Extraction and Logistic Regression](https://medium.com/@annabiancajones/sentiment-analysis-on-reviews-feature-extraction-and-logistic-regression-43a29635cc81)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f0fc0265faf3f010b6ea13d4d06fa8f6d9bd8f9a0a69886dc52220c62e8c74f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
